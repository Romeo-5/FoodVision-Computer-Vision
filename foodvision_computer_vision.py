# -*- coding: utf-8 -*-
"""FoodVision-Computer-Vision

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tCzMeGeB6G5h_pjw7YmRwCy5ffRUGCJA

# Milestone Project 1: Food Vision Big

## Check GPU

Not all GPUs are compatible with mixed precision training (computing capability of 7.0 or higher).

These include the V100 and T4 GPUs.
"""

!pip install tensorflow==2.12.1
import tensorflow as tf
tf.__version__

!nvidia-smi -L

"""## Get helper functions"""

# Download script
!wget https://raw.githubusercontent.com/Romeo-5/helper_functions/main/python_functions.py

# Import helper functions
from python_functions import create_tensorboard_callback, plot_loss_curves, compare_historys

"""## Use TensorFlow Datasets to download data"""

# Get TensorFlow Datasets
import tensorflow_datasets as tfds

# List all available datasets
datasets_list = tfds.list_builders() # get all available datasets in TFDS
print("food101" in datasets_list) # is the target dataset in the list of TFDS datasets?

# Load in the dataset
(train_data, test_data), ds_info = tfds.load(name="food101",
                                             split=["train", "validation"],
                                             shuffle_files=True,
                                             as_supervised=True, # data gets returned in tuple format (data, label)
                                             with_info=True)

"""## Exploring the Food101 data from TensorFlow Datasets

To become one with the data, I want to find:
* Class names
* The shape of our input data (image tensors)
* The datatype of our input data
* What the labels look like (e.g. are they one-hot encoded or are they label encoded)
* Do the labels match up with the class names?
"""

# Features of Food101 from TFDS
 ds_info.features

# Get the class names
class_names = ds_info.features["label"].names
class_names[:10]

# Take one sample of the train data
train_one_sample = train_data.take(1) # samples are in format (image_tensor, label)

# What does one sample of the training data look like?
train_one_sample

# Output info about the training sample
for image, label in train_one_sample:
  print(f"""
  Image shape: {image.shape}
  Image dtype: {image.dtype}
  Target class from Food101 (tensor form): {label}
  Class name (str form): {class_names[label.numpy()]}
  """)

# What does the image tensor from TFDS's Food101 look like?
image

# What are the min and max values of the image tensor?
import tensorflow as tf
tf.reduce_min(image), tf.reduce_max(image)

"""### Plot an image from TensorFlow Datasets"""

# Plot an image tensor
import matplotlib.pyplot as plt
plt.imshow(image)
plt.title(class_names[label.numpy()]) # Add title to verify the label is correct
plt.axis(False)

"""## Create preprocessing functions for the data

Neural networks perform best when data is in a certain way (e.g. batched, normalized, etc.)

However, not all data comes like this.

So in order to get it ready for a neural network, you'll often have to write preprocessing functions and map it to your data.

What I know about the data:
* In `uint8` datatype
* Compromised of all different size tensors (different sized images)
* Not scaled (the pixel values are between 0 and 255)

What I know models like:
* Data in `float32` dtype (or for mixed precision `float16` and `float32`)
* For batches, TensorFlow likes all of the tensors within a batch to be of the same size
* Scaled (values between 0 & 1) also called normalized tensors generally perform better

With these points in mind, I know what to tackle with a preprocessing function.

Since I'm going to be using an EfficientNetBX pretrained model from tf.keras.applications I don't need to rescale the data (these architectures have rescaling built-in).

This means the functions need to:
* 1. Reshape the images to all the same size
* 2. Convert the dtype of our image tensors from `uint8` to `float32`
"""

# Make a function for preprocessing images
def preprocess_img(image, label, img_shape=224):
  """
  Converts image datatype from `uint8` -> `float32` and reshapes image
  to [img_shape, img_shape, color_channels]
  """
  image = tf.image.resize(image, [img_shape, img_shape]) # reshape target image
  # image = image/255. scale image values (not required with EfficientNetBX)
  return tf.cast(image, tf.float32), label # return (float32_image, label) tuple

# Preprocess a single sample image and check the outputs
preprocessed_img = preprocess_img(image, label)[0]
print(f"Image before preprocessing:\n {image[:2]}..., \nShape: {image.shape}, \nDataType: {image.dtype}\n")
print(f"Image after preprocessing:\n {preprocessed_img[:2]}..., \nShape: {preprocessed_img.shape}, \nDataType: {preprocessed_img.dtype}\n")

"""## Batch & Prepare datasets

For more resources on improving efficiency of data input pipeline performance: https://www.tensorflow.org/guide/data_performance
"""

# Map preprocessing function to training data (and parallelize)
train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)
# Shuffle train data and turn it into batches and prefetch it (load it faster)
train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)

# Map preprocessing function to test data
test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)

train_data, test_data

"""## Creating modelling callbacks

* TensorBoard callback to log training results (to visualize them later if need be)
* ModelCheckpoint callback to save the model progress after feature extraction
"""

# Create tensorboard callback (import from script)
from python_functions import create_tensorboard_callback

# Creat ModelCheckpoint callback to save a model's progress during training
checkpoint_path = "model_checkpoints/cp.ckpt"
model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,
                                                      monitor="val_acc",
                                                      save_best_only=True,
                                                      save_weights_only=True,
                                                      verbose=0)

"""## Setup mixed precision training

For more info on mixed precision training in TensorFlow: https://www.tensorflow.org/guide/mixed_precision

Mixed precision utilizes a combination of float32 and float16 data types to speed up model performance.
"""

# Turn on mixed precision training
from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy("mixed_float16") # set global data policy to mixed precision

mixed_precision.global_policy()

"""## Build feature extraction model"""

from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing

# Create base model
input_shape = (224, 224, 3)
base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model.trainable = False

# Create functional model
inputs = layers.Input(shape=input_shape, name="input_layer")
# x = preprocessing.Rescaling(1./255)(x) # rescale if necessary
x = base_model(inputs, training=False) # make sure layers which should be in inference mode stay that way
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(len(class_names))(x)
outputs = layers.Activation("softmax", dtype=tf.float32, name="softmax_float32")(x)
model = tf.keras.Model(inputs, outputs)

# Compile the model
model.compile(loss="sparse_categorical_crossentropy",
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

model.summary()

"""## Checking layer dtype policies"""

# Check the dtype_policy attributes of layers in the model
for layer in model.layers:
  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)

"""Going through the above we see:
* `layer.name`: the human readable name of a particular layer
* `layer.trainable`: is the layer trainable or not? (if `False`, the weights are frozen)
* `layer.dtype`: the data type a layer stores its variables in
* `layer.dtype_policy`: the data type policy a lyaer computes on its variables with
"""

# Check the dtype_policy attributes of layers in the base model
for layer in model.layers[1].layers[:20]: # check the layer of the base model (at index 1 of `model`)
  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)

"""## Fit the feature extraction model

If the end goal is to fine-tune a pretrained model, the general order of doing things is:
1. Build a feature extraction model (train a couple output layers with base layers frozen)
2. Fine-tune some of the frozen layers
"""

# Fit feature extraction model with callbacks
historys_101_food_classes_feature_extract = model.fit(train_data,
                                                      epochs=3,
                                                      steps_per_epoch=len(train_data),
                                                      validation_data=test_data,
                                                      validation_steps=int(0.15*len(test_data)),
                                                      callbacks=[create_tensorboard_callback(dir_name="training_logs",
                                                                                             experiment_name="efficientnetb0_101_classes_all_data_feature_extract"),
                                                                 model_checkpoint])

# Evaluate model on whole test dataset
results_feature_extract_model = model.evaluate(test_data)
results_feature_extract_model

"""## Save the whole model to file"""

# Save model locally
# model.save("drive/MyDrive/TensorFlow/101_food_classes_feature_extract_model")

# Load model saved above
# loaded_model = tf.keras.models.load_model("drive/MyDrive/TensorFlow/101_food_classes_feature_extract_model")

"""## Downloading model and preparing model for fine-tuning"""

# Download the saved model from Google Storage
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip

# Unzip the SavedModel downloaded from Google Stroage
!mkdir downloaded_gs_model # create new dir to store downloaded feature extraction model
!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model

# Load and evaluate downloaded GS model
loaded_gs_model = tf.keras.models.load_model("downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision")

# Get a summary of our downloaded model
loaded_gs_model.summary()

# How does the loaded model perform?
results_loaded_gs_model = loaded_gs_model.evaluate(test_data)
results_loaded_gs_model

# Are any of the layers in the model frozen?
for layer in loaded_gs_model.layers:
    layer.trainable = True # set all layers to trainable
    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy) # make sure loaded model is using mixed precision dtype_policy ("mixed_float16")

# Check the layers in the base model and see what dtype policy they're using
for layer in loaded_gs_model.layers[1].layers[:20]:
    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)

"""## More callbacks

I'm about to start fine-tuning a deep learning model with over 200 layers using over 100,000 (75k+ training, 25K+ testing) images, which means our model's training time is probably going to be much longer than before.

It could be a couple of hours or in the case of the [DeepFood paper](https://arxiv.org/pdf/1606.05675.pdf) (the baseline I'm trying to beat), their best performing model took 2-3 days of training time.

There's a solution: the [`EarlyStopping` callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping).

The `EarlyStopping` callback monitors a specified model performance metric (e.g. `val_loss`) and when it stops improving for a specified number of epochs, automatically stops training.

Using the `EarlyStopping` callback combined with the `ModelCheckpoint` callback saving the best performing model automatically, I could keep our model training for an unlimited number of epochs until it stops improving.

I can set up both of these up to monitor our model's `val_loss`.
"""

# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs
early_stopping = tf.keras.callbacks.EarlyStopping(monitor="val_loss", # watch the val loss metric
                                                  patience=3) # if val loss decreases for 3 epochs in a row, stop training

# Create ModelCheckpoint callback to save best model during fine-tuning
checkpoint_path = "fine_tune_checkpoints/"
model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,
                                                      save_best_only=True,
                                                      monitor="val_loss")

"""[`ReduceLROnPlateau`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau).

Like the `ModelCheckpoint` and `EarlyStopping` callbacks, the `ReduceLROnPlateau` callback montiors a specified metric and when that metric stops improving, it reduces the learning rate by a specified factor (e.g. divides the learning rate by 10).

Once the validation loss stops improving for two or more epochs, I'll reduce the learning rate by a factor of 5 (e.g. `0.001` to `0.0002`).

To make sure the learning rate doesn't get too low (and potentially result in our model learning nothing), I'll set the minimum learning rate to `1e-7`.
"""

# Creating learning rate reduction callback
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor="val_loss",
                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)
                                                 patience=2,
                                                 verbose=1, # print out when learning rate goes down
                                                 min_lr=1e-7)

"""## Fine-tuned model"""

# Compile the model
loaded_gs_model.compile(loss="sparse_categorical_crossentropy", # sparse_categorical_crossentropy for labels that are *not* one-hot
                        optimizer=tf.keras.optimizers.Adam(0.0001), # 10x lower learning rate than the default
                        metrics=["accuracy"])

# Start to fine-tune (all layers)
history_101_food_classes_all_data_fine_tune = loaded_gs_model.fit(train_data,
                                                        epochs=100, # fine-tune for a maximum of 100 epochs
                                                        steps_per_epoch=len(train_data),
                                                        validation_data=test_data,
                                                        validation_steps=int(0.15 * len(test_data)), # validation during training on 15% of test data
                                                        callbacks=[create_tensorboard_callback("training_logs", "efficientb0_101_classes_all_data_fine_tuning"), # track the model training logs
                                                                   model_checkpoint, # save only the best model during training
                                                                   early_stopping, # stop model after X epochs of no improvements
                                                                   reduce_lr]) # reduce the learning rate after X epochs of no improvements

# How does the fine-tuned model perform?
results_loaded_gs_model = loaded_gs_model.evaluate(test_data)
results_loaded_gs_model

"""> Model is attaining comparable ~80% results as the DeepFood paper in only 5 epochs!"""

# Get a summary of the fine-tuned model
loaded_gs_model.summary()

# Upload experiment results to TensorBoard (uncomment to run)
!tensorboard dev upload --logdir ./training_logs \
   --name "Fine-tuning EfficientNetB0 on all Food101 Data" \
   --description "Training results for fine-tuning EfficientNetB0 on Food101 Data with learning rate 0.0001" \
   --one_shot